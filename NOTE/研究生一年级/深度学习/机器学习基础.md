# 机器学习基础

## 奥卡姆剃刀准则

如无必要，勿增实体；  

&emsp;欠拟合：提高模型复杂度(决策树，拓展分支；神经网络：增加训练轮数)  
&emsp;过拟合：降低模型复杂度(优化目标加正则项；决策树：减枝；神经网络：early stop，dropout)  
对测试样本 $x$ 令 $y_D$  为 $x$ 在数据集中的标记，$y$  为 $x$  的真实标记，$f(x,D)$ 为训练集$D$ 上学得模型$f$ 在$x$ 上的预测输出  
泛化误差指模型在不同训练集上损失的期望
$$
\begin{aligned}
    &E(f;D) = E_D[(f(x;D)-y_D)^2] = E_D [(f(x;D)^2]-(\hat{f} - y)^2 +E_D[(y_D - y)^2] \\
    &E(f;D) = bias^2 (x) + var (x) +\epsilon^2
\end{aligned}
$$
boosting ： 减少偏差  
bagging ： 减少方差  
欠拟合阶段，偏差较大，过拟合阶段，方差变大

## 模型选择方法

1. 留出法
2. k折交叉验证：常见 10次10折交叉验证
3. 留一法
4. 自助法(bootstrapping):适用于小样本
